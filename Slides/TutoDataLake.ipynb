{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuto utilisation du cluster\n",
    "\n",
    "Objectif de ce notebook est d'illustrer comment utiliser le clusteur de données pour accélérer des calculs d'analyse de données avec des données issus de base de type MongoDB et/ou Rasdaman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/ Architecture du cluster\n",
    "\n",
    "### A/ Infrastructure physique\n",
    "\n",
    "- 1 machine « Edge » ayant :\n",
    "  - 128 G de RAM\n",
    "  - 12 processeurs bi-cœurs\n",
    "  - 4 * 2 To de disque HDD\n",
    "- 2 machines « Master » ayant chacune :\n",
    "  - 128 G de RAM\n",
    "  - 8 processeurs bi-cœurs\n",
    "  - 6 * 2 To de disque HDD\n",
    "- 7 machines « Workers type 1 » ayant chacune :\n",
    "  - 192 G de RAM\n",
    "  - 12 processeurs bi-cœurs\n",
    "  - 11 * 4 To de disque HDD\n",
    "- 4 machines « Workers type 2 » ayant chacune :\n",
    "  - 384 G de RAM\n",
    "  - 14 processeurs bi-cœurs\n",
    "  - 12 * 960 Go de disque SSD\n",
    "- 1 machine « Worker type 3 » ayant :\n",
    "  - 768 G de RAM\n",
    "  - 14 processeurs bi-cœurs\n",
    "  - 12 * 960 Go de disque SSD\n",
    "\n",
    "### B/ Urbanisation du clusteur\n",
    "Le cluster est composé des machines suivantes :\n",
    " \n",
    "#### Machines Edge :\n",
    "- edg01 :\n",
    "  - Dropzone (disk 3)\n",
    "  - NiFi (data disk 2)\n",
    "  - Zeppelin  (http://islin-hdpmas1.ifp.fr:8999)\n",
    "  - Superset\n",
    "  - Grafana\n",
    "  - Jupyter (http://islin-hdpledg01.ifp.fr)\n",
    "  - Sqoop client\n",
    "  - Oracle SQLplus\n",
    "  - Knox Gateway\n",
    "  - Ranger Admin\n",
    "  - Rstudio\n",
    "  - Ambari (https://islin-hdpmas01.ifp.fr:8080)\n",
    "\n",
    "#### Machines Master :\n",
    "- mas01 :\n",
    "  - Namenode - active (disk 2, 3)\n",
    "  - YARN NodeManager (active)\n",
    "(disk 2, 3)\n",
    "- mas02 :\n",
    "  - Namenode - standby (disk 2, 3)\n",
    "  - YARN NodeManager (standby)\n",
    "  - Hive Server (logs sur le /disk6)\n",
    "  - MongoDB : islin-hdplmas02.ifp.fr\n",
    "      - islin-hdplnod01.ifp.fr\n",
    "      - islin-hdplnod02.ifp.fr\n",
    "      - islin-hdplnod03.ifp.fr\n",
    "      - pymongo-client :  (edg01, nod01, nod02 et nod03)\n",
    "\n",
    "#### Machines Worker :\n",
    "- nod06, nod07, nod08, nod09\n",
    "(type 1) :\n",
    "  - Datanode (disk 2, 3, 4)\n",
    "  - Kafka Broker (disk 5, 6, 7)\n",
    "  - HBase RegionServer (disk 8, 9)\n",
    "  - Zookeeper data dir (disk 10)\n",
    "  - nod10, nod11, nod12 (type 1) :\n",
    "  - Solr\n",
    "  - Zookeeper for Solr\n",
    "- nod01, nod02, nod03 (type 2) :\n",
    "  - ArangoDB (disk 2, 3, 4)\n",
    "  - MongoDB (disk 5, 6, 7)\n",
    "- nod04 (type 2) :\n",
    "  - Kubernetes :\n",
    "  - InfluxDB\n",
    "  - ChronoGraph https://islin-hdplnod04:8888\n",
    "- nod05 (type 3) :\n",
    "  - Datascience (nœud GPU)\n",
    "\n",
    "#### Noms et adresse IP des noeuds\n",
    "\n",
    "-  edg01 islin-hdpledg01.ifp.fr 10.126.51.131\n",
    "-  mas01 islin-hdplmas01.ifp.fr 10.126.51.121\n",
    "-  mas02 islin-hdplmas02.ifp.fr 10.126.51.122\n",
    "-  nod01 islin-hdplnod01.ifp.fr 10.126.51.101\n",
    "-  nod02 islin-hdplnod02.ifp.fr 10.126.51.102\n",
    "-  nod03 islin-hdplnod03.ifp.fr 10.126.51.103\n",
    "-  nod04 islin-hdplnod04.ifp.fr 10.126.51.104\n",
    "-  nod05 islin-hdplnod05.ifp.fr 10.126.51.105\n",
    "-  nod06 islin-hdplnod06.ifp.fr 10.126.51.106\n",
    "-  nod07 islin-hdplnod07.ifp.fr 10.126.51.107\n",
    "-  nod08 islin-hdplnod08.ifp.fr 10.126.51.108\n",
    "-  nod09 islin-hdplnod09.ifp.fr 10.126.51.109\n",
    "-  nod10 islin-hdplnod10.ifp.fr 10.126.51.110\n",
    "-  nod11 islin-hdplnod11.ifp.fr 10.126.51.111\n",
    "-  nod12 islin-hdplnod12.ifp.fr 10.126.51.112\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II/ HPC sur le cluster avec python et Dask\n",
    "\n",
    "### A/ Configuration de l'environnement\n",
    "\n",
    "#### 1) Prérequis\n",
    "\n",
    "a) Avoir créer une répertoire /disk4/conda/<user> ou avoir accès à /home/irsrvshare2/R11/dgt_sandb/conda\n",
    "    \n",
    "b) Accès à conda :\n",
    "-  /usr/local/Anaconda3-2019.03-Linux-x86_64\n",
    "-  ou dans ~commonlib \n",
    "    - export MODULEPATH=~commonlib/ifpen/centos_7/modules/all:$MODULEPATH\n",
    "    - module load anaconda3/2020.0 \n",
    "    \n",
    "```bash\n",
    "export PATH=/usr/local/Anaconda3-2019.03-Linux-x86_64/bin:$PATH\n",
    "export LD_LIBRARY_PATH=/usr/local/Anaconda3-2019.03-Linux-x86_64/lib:$LD_LIBRARY_PATH\n",
    "export CONDA_ENVS_PATH=/disk4/conda/<user>/env\n",
    "export CONDA_PKGS_DIRS=/disk4/conda/<user>/pkgs\n",
    "export https_proxy=irproxy:8082\n",
    "```\n",
    "\n",
    "\n",
    "c) Initialiser conda :\n",
    "    \n",
    "```bash\n",
    "conda init\n",
    "conda config --set proxy_servers.http http://irproxy:8082\n",
    "conda config --set proxy_servers.https https://irproxy:8082\n",
    "```\n",
    "\n",
    "#### 2) Création et packaging d'environnemnt conda utilisateur\n",
    "\n",
    "Exemple environnement pour faire du dask, Rasdaman et traitement sur des images 3D\n",
    "\n",
    "\n",
    "```bash\n",
    "conda create -n img3D-env pthon=3.7\n",
    "conda install -n img3D-env -c conda-forge [list des dependances packages ]\n",
    "```\n",
    "\n",
    "ou utilistation d'un fichier yaml du type img3D-environment.yml\n",
    "```bash\n",
    "name: img3D-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.7\n",
    "  - jupyterlab>=2.0.0\n",
    "  - numpy>=1.18.1\n",
    "  - h5py\n",
    "  - scipy>=1.3.0\n",
    "  - toolz\n",
    "  - dask=2.11.0\n",
    "  - dask-labextension>=2.0.0\n",
    "  - distributed=2.11.0\n",
    "  - dask-yarn\n",
    "  - matplotlib\n",
    "  - pandas>=1.0.1\n",
    "  - pandas-datareader\n",
    "  - pytables\n",
    "  - scikit-learn>=0.22.1\n",
    "  - scikit-image>=0.15.0\n",
    "  - ujson\n",
    "  - pip\n",
    "  - s3fs\n",
    "```\n",
    "\n",
    "Exemple de fichier pour rasdaman :\n",
    "```bash\n",
    "name: rasdaman-env\n",
    "channels:\n",
    "- conda-forge/label/cf202003\n",
    "dependencies:\n",
    "- python=3.7\n",
    "- numpy\n",
    "- pygrib\n",
    "- jsonschema\n",
    "- python-dateutil\n",
    "- lxml\n",
    "- grpcio\n",
    "- protobuf\n",
    "- matplotlib\n",
    "```\n",
    "\n",
    "Creation d'environnement à partir de fichier yaml :\n",
    "```bash\n",
    "conda env create -f img3D-environment.yml\n",
    "```\n",
    "\n",
    "\n",
    "Finalisation avec des packages spécifiques :\n",
    "```bash\n",
    "conda env list # pour avoir la liste des env disponibles\n",
    "conda activate img3D-env\n",
    "\n",
    "cd /path_to_rasdaman/rasdapy3\n",
    "python setup.py install\n",
    "\n",
    "cd /path_to_r11img/r11img\n",
    "python setup.py install\n",
    "\n",
    "cd /path_to_drp4m/drp4ml\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "Packaging de l'environnement\n",
    "```bash\n",
    "conda pack -o img3d-env.tar.gz\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C/ Simple soumission de job en mode Single Machine\n",
    "\n",
    "La façon la plus simple d'utiliser Dask sur un neoud simple\n",
    "\n",
    "Il suffit d'écrire puis lancer des scripts dask de la forme:\n",
    "\n",
    "```bash\n",
    "import dask as da\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=4)\n",
    "\n",
    "def square(x):\n",
    "        return x ** 2\n",
    "\n",
    "array = [ delayed(square)(i) for i in range(10))\n",
    "\n",
    "results = da.compute(*array)\n",
    "\n",
    "print('Results',results)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D/ Soumission de job en mode Cluster\n",
    "\n",
    "### 1) Gestion du cluster à a la main\n",
    "\n",
    "Cela consiste à configurer manuellement un cluster dask avec =\n",
    "- un scheduler\n",
    "- plusieur worker sur différent noeuds du cluster\n",
    "\n",
    "La difficulté est de bien s'assurer que sur chaque neuds, les environnements python sont bien accessibles et activés.\n",
    "\n",
    "Il faut gérer aussi ces variables $PYTHONPATH pour avoir accès à tous ces modules\n",
    "\n",
    "\n",
    "Exemple :\n",
    "- un scheduler sur le noeuds islin-hpdledg01\n",
    "- un worker avec 4 processus et 2 threads par process sur les noeuds islin-hpdlnod[06,07,08,09]\n",
    "- un worker avec 4 processus et 1 GPU et 100GB de mémoire ilslin-hplnode05\n",
    "\n",
    "\n",
    "```bash\n",
    "> ssh islin-hpdledg01\n",
    "> bash\n",
    "> (base) conda activate img3D-env\n",
    "> (img3D-env) dask-scheduler\n",
    "\n",
    "Port 8787 is already in use.\n",
    "Perhaps you already have a cluster running?\n",
    "Hosting the diagnostics dashboard on a random port instead.\n",
    "  warnings.warn(\"\\n\" + msg)\n",
    "distributed.scheduler - INFO -   Scheduler at:  tcp://10.126.51.131:8786\n",
    "distributed.scheduler - INFO -   dashboard at:                    :40299\n",
    "```\n",
    "\n",
    "sur chaque noeuds islin-hpdlnod[06,07,08,09]\n",
    "\n",
    "```bash\n",
    "> ssh islin-hpdlnod06\n",
    "> bash\n",
    "> (base) conda activate img3D-env\n",
    "> (img3D-env) dask-worker tcp://10.126.51.131:8786 --nprocs 4 --nthreads 2\n",
    "```\n",
    "sur le noeuds islin-hplnod05, lancement avec un GPU\n",
    "\n",
    "```bash\n",
    "> ssh islin-hpdlnod05\n",
    "> bash\n",
    "> (base) conda activate img3D-env\n",
    "> (img3D-env) dask-worker tcp://10.126.51.131:8786 --nprocs 4 --resources \"GPU=1\" --resources \"MEMORY=100e9\"\n",
    "```\n",
    "\n",
    "on peut alors lancer des scripts dask de la forme :\n",
    "```bash\n",
    "from dask.distributed import Client\n",
    "client = Client('10.126.51.131:8786')\n",
    "def square(x):\n",
    "        return x ** 2\n",
    "\n",
    "def neg(x):\n",
    "        return -x\n",
    "\n",
    "A = client.map(square, range(10))\n",
    "B = client.map(neg, A)\n",
    "total = client.submit(sum, B)\n",
    "print('RESULT:'total.result())\n",
    "print('A=',client.gather(A)\n",
    "```\n",
    "\n",
    "Exemple de script nécessitant des ressources particulières de type GPU ou quantité mémoire.\n",
    "```bash\n",
    "from dask.distributed import Client\n",
    "client = Client('10.126.51.131:8786')\n",
    "\n",
    "data = [client.submit(load, fn) for fn in filenames]\n",
    "processed = [client.submit(process, d, resources={'GPU': 1}) for d in data]\n",
    "final = client.submit(aggregate, processed, resources={'MEMORY': 70e9})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Gestion du cluster en mode SSH\n",
    "\n",
    "#### a) Prérequis\n",
    "\n",
    "- configuration SSH sur tous les noeuds (clé, et authorized_key bien configuré)\n",
    "- vérifier que l on peut se connecter d'un noeuds à l autre sans mot de passe\n",
    "- module paramiko bien installé dans l environnement python, sinon\n",
    ":\n",
    "```bash\n",
    "conda install -c conda-forge -n img3D-env paramiko asyncssh\n",
    "```\n",
    "\n",
    "#### b) Utilisation de l utilitaire dask-ssh\n",
    "\n",
    "On peut utiliser l'utilitaire dask-ssh pour configurer le clusteur\n",
    "\n",
    "\n",
    "On crée un fichier hostfile.txt avec un host pour le scheduler et une liste de host pour les workers\n",
    "\n",
    "```bash\n",
    "$ cat hostfile.txt\n",
    "islin-hdpledg01.ifp.fr\n",
    "islin-hdplnod06.ifp.fr \n",
    "islin-hdplnod07.ifp.fr \n",
    "islin-hdplnod08.ifp.fr \n",
    "islin-hdplnod09.ifp.fr \n",
    "\n",
    "$ dask-ssh --hostfile hostfile.txt --nprocs 4 --nthreads 2 --remote-python 'path_to_correct_python_from_user_env'\n",
    "```\n",
    "\n",
    "ensuite les scripts ont la forme suivante :\n",
    "\n",
    "```bash\n",
    "from dask.distributed import Client, SSHCluster\n",
    "\n",
    "nodelist = ['edg01','nod06','nod07','nod08','nod09']\n",
    "SSHCluster cluster(nodelist)\n",
    "client = Client(cluster)\n",
    "\n",
    "def square(x):\n",
    "        return x ** 2\n",
    "\n",
    "def neg(x):\n",
    "        return -x\n",
    "\n",
    "A = client.map(square, range(10))\n",
    "B = client.map(neg, A)\n",
    "total = client.submit(sum, B)\n",
    "print('RESULT:'total.result())\n",
    "print('A=',client.gather(A)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Gestion du cluster en mode YARN\n",
    "\n",
    "#### a) Initialisation Kerberos\n",
    "\n",
    "```bash\n",
    "$ kinit user@HADOOP.IFP.FR -k -t /tmp/user.keytab\n",
    "```\n",
    "\n",
    "#### b) Forme des scripts dask\n",
    "\n",
    "```bash\n",
    "import time\n",
    "import dask.array as da\n",
    "from dask_yarn import YarnCluster\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "# Create a cluster where each worker has two cores and eight GiB of memory\n",
    "cluster = YarnCluster(environment='img3D-env.tar.gz',\n",
    "                      worker_vcores=2,\n",
    "                      worker_memory=\"2GiB\",\n",
    "                      n_workers=6,\n",
    "                      deploy_mode='local',\n",
    "                      dashboard_address=':8789')\n",
    "   \n",
    "# Connect to the cluster\n",
    "client = Client(cluster)\n",
    "\n",
    "def square(x):\n",
    "        return x ** 2\n",
    "\n",
    "def neg(x):\n",
    "        return -x\n",
    "\n",
    "A = client.map(square, range(10))\n",
    "B = client.map(neg, A)\n",
    "total = client.submit(sum, B)\n",
    "print('RESULT:'total.result())\n",
    "print('A=',client.gather(A)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III/ HPC sur le cluster avec python et Spark\n",
    "\n",
    "### A/ Configuration de l'environnement\n",
    "\n",
    "#### 1) Prérequis\n",
    "\n",
    "a) Avoir créer une répertoire /disk4/conda/<user>\n",
    "    \n",
    "b) Accès à conda :\n",
    "-  /usr/local/Anaconda3-2019.03-Linux-x86_64\n",
    "-  ou dans ~commonlib : module load anaconda3/2020.0\n",
    "    \n",
    "```bash\n",
    "export PATH=/usr/local/Anaconda3-2019.03-Linux-x86_64/bin:$PATH\n",
    "export LD_LIBRARY_PATH=/usr/local/Anaconda3-2019.03-Linux-x86_64/lib:$LD_LIBRARY_PATH\n",
    "export CONDA_ENVS_PATH=~dgt_sandb/conda/env\n",
    "export CONDA_PKGS_DIRS=~dgt_sandb/pkgs\n",
    "export https_proxy=irproxy:8082\n",
    "```\n",
    "\n",
    "c) Initialiser conda :\n",
    "    \n",
    "```bash\n",
    "conda init\n",
    "conda config --set proxy_servers.http http://irproxy:8082\n",
    "conda config --set proxy_servers.https https://irproxy:8082\n",
    "```\n",
    "\n",
    "#### 2) Création et packaging d'environnemnt conda utilisateur\n",
    "\n",
    "Exemple environnement pour faire pySpark, Rasdaman et traitement sur des images 3D\n",
    "\n",
    "\n",
    "```bash\n",
    "conda create -n img3D-spark-env pthon=3.7\n",
    "conda install -n img3D-spark-env -c conda-forge [list des dependances packages ]\n",
    "```\n",
    "\n",
    "ou utilistation d'un fichier yaml du type img3D-environment.yml\n",
    "```bash\n",
    "name: img3D-spark-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.7\n",
    "  - jupyterlab>=2.0.0\n",
    "  - numpy>=1.18.1\n",
    "  - h5py\n",
    "  - scipy>=1.3.0\n",
    "  - toolz\n",
    "  - dask=2.11.0\n",
    "  - dask-labextension>=2.0.0\n",
    "  - distributed=2.11.0\n",
    "  - dask-yarn\n",
    "  - matplotlib\n",
    "  - pandas>=1.0.1\n",
    "  - pandas-datareader\n",
    "  - pytables\n",
    "  - scikit-learn>=0.22.1\n",
    "  - scikit-image>=0.15.0\n",
    "  - ujson\n",
    "  - pip\n",
    "  - s3fs\n",
    "```\n",
    "\n",
    "Exemple de fichier pour rasdaman :\n",
    "```bash\n",
    "name: rasdaman-env\n",
    "channels:\n",
    "- conda-forge/label/cf202003\n",
    "dependencies:\n",
    "- python=3.7\n",
    "- numpy\n",
    "- pygrib\n",
    "- jsonschema\n",
    "- python-dateutil\n",
    "- lxml\n",
    "- grpcio\n",
    "- protobuf\n",
    "- matplotlib\n",
    "```\n",
    "\n",
    "Creation d'environnement à partir de fichier yaml :\n",
    "```bash\n",
    "conda env create -f img3D-spark-environment.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
