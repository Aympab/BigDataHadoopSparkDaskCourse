{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook : Iris Multi-classification problem : A Spark + MLLib approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf, SparkContext,  SparkFiles\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,  LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Setting Spark Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Local Configuration \n",
    "sconf =  SparkConf()\n",
    "sconf.setAppName(\"irisPreds\")\n",
    "sconf.setMaster(\"local[1]\")\n",
    "sconf.set('spark.executor.memory', '4g')\n",
    "sconf.set('spark.executor.cores', 8)\n",
    "sconf.set('spark.logConf', True)\n",
    "\n",
    "#Spark Context\n",
    "sc = SparkContext(conf=sconf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Loading & Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- variety: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisData = sqlContext.createDataFrame(pd.read_csv(\"iris.csv\"))\n",
    "irisData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gathering features together into ML models supported format (inputCols)\n",
    "vecAssembler = VectorAssembler( inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\",\"petal_width\"], \n",
    "                              outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric indexing of the target variable\n",
    "labellizer = StringIndexer(inputCol=\"variety\", \n",
    "                           outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features set (mean + std)\n",
    "scaler = StandardScaler(inputCol=\"features\", \n",
    "                        outputCol=\"scaled\", \n",
    "                        withStd=True, \n",
    "                        withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training/testing sets\n",
    "(train, test)   = irisData.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated Preprocessing Pipeline\n",
    "dataPreprocessor = Pipeline( stages=[vecAssembler, labellizer, scaler]).fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. ML Modeling, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML Models\n",
    "## 1 - Decision Tree\n",
    "dtClassifier = DecisionTreeClassifier(labelCol=\"label\", \n",
    "                                      featuresCol=\"scaled\", \n",
    "                                      maxDepth=4)\n",
    "## 2 - Logistic Regression\n",
    "lrClassifier  = LogisticRegression(labelCol=\"label\", \n",
    "                                   featuresCol=\"scaled\", \n",
    "                                   maxIter=30)\n",
    "\n",
    "## 3 - Random Forest\n",
    "rfClassifier = RandomForestClassifier(labelCol=\"label\", \n",
    "                                      featuresCol=\"scaled\",\n",
    "                                      numTrees=20,\n",
    "                                      maxDepth=3,\n",
    "                                      minInstancesPerNode=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Pipeline\n",
    "readyTrain  = dataPreprocessor.transform(train)\n",
    "readyTest   = dataPreprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models objects fitting\n",
    "dtModel     = dtClassifier.fit(readyTrain)\n",
    "lrModel     = lrClassifier.fit(readyTrain)\n",
    "rfModel     = rfClassifier.fit(readyTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test data\n",
    "dtPreds  = dtModel.transform(readyTest)\n",
    "lrPreds  = lrModel.transform(readyTest)\n",
    "rfPreds  = rfModel.transform(readyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the train data\n",
    "dtPredsTrain  = dtModel.transform(readyTrain)\n",
    "lrPredsTrain  = lrModel.transform(readyTrain)\n",
    "rfPredsTrain = rfModel.transform(readyTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating accuracy\n",
    "accEvaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", \n",
    "                                                 labelCol=\"label\", \n",
    "                                                 metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtTrainAcc = accEvaluator.evaluate(dtPredsTrain)\n",
    "dtTestAcc =  accEvaluator.evaluate(dtPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrTrainAcc = accEvaluator.evaluate(lrPredsTrain)\n",
    "lrTestAcc =  accEvaluator.evaluate(lrPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfTrainAcc = accEvaluator.evaluate(rfPredsTrain)\n",
    "rfTestAcc =  accEvaluator.evaluate(rfPreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Decision Tree:  0.9831932773109243\n",
      "[TRAIN] Logistic Regression:  0.9831932773109243\n",
      "[TRAIN] Random Forest:  0.9663865546218487\n"
     ]
    }
   ],
   "source": [
    "print(\"[TRAIN] Decision Tree: \", dtTrainAcc)\n",
    "print(\"[TRAIN] Logistic Regression: \",lrTrainAcc )\n",
    "print(\"[TRAIN] Random Forest: \" , rfTrainAcc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] Decision Tree:  0.967741935483871\n",
      "[TEST] Logistic Regression:  0.967741935483871\n",
      "[TEST] Random Forest:  0.9032258064516129\n"
     ]
    }
   ],
   "source": [
    "print(\"[TEST] Decision Tree: \", dtTestAcc)\n",
    "print(\"[TEST] Logistic Regression: \", lrTestAcc)\n",
    "print(\"[TEST] Random Forest: \" , rfTestAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing Context\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
